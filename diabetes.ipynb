{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84853047",
   "metadata": {},
   "source": [
    "# Precious Kings\n",
    "## Project Title: Time Series Predictive Modeling Diabetes Progression and Health Risk Stratification Using Electronic Health Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606615b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully Precious\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # Though we might not split for simplicity here\n",
    "from sklearn.ensemble import RandomForestClassifier # Import RandomForest\n",
    "from sklearn.preprocessing import StandardScaler     # For scaling features\n",
    "import pickle                                       # For saving the model and scaler\n",
    "import os                                           # To check if the file exists\n",
    "\n",
    "print(\"Libraries imported successfully Precious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7f5ca",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01438b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')  # Replace with your actual dataset path\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e2d0c",
   "metadata": {},
   "source": [
    "###  Define Features (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b87169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) and Target (y) defined.\n",
      "Shape of X: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Define the list of feature column names\n",
    "# Make sure these match your CSV column names EXACTLY!\n",
    "feature_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target_col = 'Outcome'\n",
    "\n",
    "# Create the features DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# Create the target Series (y)\n",
    "y = data[target_col]\n",
    "\n",
    "print(\"Features (X) and Target (y) defined.\")\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb9ccb",
   "metadata": {},
   "source": [
    "###  Preprocess Data: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0eac683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled using StandardScaler.\n",
      "\n",
      "Scaler is fitted and ready to be saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features (X) and transform X\n",
    "# fit_transform() does both steps in one go\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Features scaled using StandardScaler.\")\n",
    "\n",
    "# You can optionally convert X_scaled back to a DataFrame to view it nicely (optional)\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "# print(\"\\nFirst 5 rows of scaled features:\")\n",
    "# print(X_scaled_df.head())\n",
    "\n",
    "print(\"\\nScaler is fitted and ready to be saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8abdf",
   "metadata": {},
   "source": [
    "### Train the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e51bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier model\n",
    "# n_estimators is the number of trees in the forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42) # random_state for reproducibility\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "print(\"Random Forest Classifier model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ad5ce",
   "metadata": {},
   "source": [
    "### Save the Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fadce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully as 'diabetes_rf_model.pkl'\n",
      "Scaler saved successfully as 'scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Define filenames for the saved files\n",
    "model_filename = 'diabetes_rf_model.pkl' # Updated filename\n",
    "scaler_filename = 'scaler.pkl'\n",
    "\n",
    "# Save the trained model\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "print(f\"Model saved successfully as '{model_filename}'\")\n",
    "\n",
    "# Save the fitted scaler\n",
    "with open(scaler_filename, 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "print(f\"Scaler saved successfully as '{scaler_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648af465",
   "metadata": {},
   "source": [
    "### Predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aabcce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions: [1 0 1 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model\n",
    "predictions = model.predict(X_scaled)\n",
    "\n",
    "# Display the first 10 predictions\n",
    "print(\"First 10 predictions:\", predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7610a",
   "metadata": {},
   "source": [
    "### Calculate the F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9343287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import the f1_score function\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y, predictions)\n",
    "\n",
    "# Display the F1 score\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
